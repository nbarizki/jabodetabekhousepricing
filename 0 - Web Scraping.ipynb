{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access website using `Chrome Webdriver`, one must verify that:\n",
    "\n",
    "1. `Chrome` (denotes the *fully installed version of Chrome Browser*) must be installed in the system. Identify the **installed version** of *Chrome* first.\n",
    "2. `Chrome Webdriver` must be provided, which its **version** shall match the **installed version** of `Chrome`. Further explanation on this can be found in https://chromedriver.chromium.org/downloads/version-selection. Download the matched version of `Chrome Webdriver`, the file name will be `chromedriver.exe`.\n",
    "3. Make sure that `Chrome Webdriver` can be detected while utilizing `Selenium` from python. I choose to add the `chromedriver.exe` executable file path to ChromeDriver when instantiating `webdriver.Chrome`.\n",
    "\n",
    " <center><img src=\"Scraped_Data\\pic\\1_chromedriver_version.png\"/></center>\n",
    "\n",
    " *<center> Matching `Chrome` version with `Chrome Webdriver` version</center>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Web Scraping Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from numpy import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.rumah123.com/jual/residensial/?place[]=dki-jakarta&place[]=bogor&place[]=depok&place[]=bekasi,bekasi&placeId[]=8de06376-49a3-4369-a01b-00085aefe766&placeId[]=dfd71096-eda2-4776-b3ca-542d8c5fb12b&placeId[]=a4a34395-ebe5-4930-9456-df327a9f484a&placeId[]=66899e8e-4896-467b-8e54-ab7c533bd616#qid~a0314d88-70ff-4b6c-b4bd-45f4c9f41d04'\n",
    "browser = webdriver.Chrome('D:\\\\chromedriver.exe')\n",
    "browser.implicitly_wait(10)\n",
    "browser.get(URL)\n",
    "time.sleep(float(random.uniform(5, 180, 1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Accessing `main entry list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the house listings in main page is stored in `listing-container` as below snapshot. We are going to retrieve all of the listings in a single page by accessing this `XPath`.\n",
    "\n",
    "\n",
    " <center><img src=\"Scraped_Data\\pic\\2_Main_content.png\"/></center>\n",
    "\n",
    " <center><img src=\"Scraped_Data\\pic\\3_Listing_card.png\"/></center>\n",
    "\n",
    " *<center> Webpage structure of house listing </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"5a67e7b79fb99de414f0dbe9ce05b762\", element=\"7e5a1895-163d-4036-a40e-a0127ff97dee\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a67e7b79fb99de414f0dbe9ce05b762\", element=\"3e9e4682-7c93-4ded-8af0-e261feb77134\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a67e7b79fb99de414f0dbe9ce05b762\", element=\"757df6dd-c6c9-462a-a241-3d4ffbae3ac3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a67e7b79fb99de414f0dbe9ce05b762\", element=\"44630d51-b024-4695-96a1-70d6206fd0cf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a67e7b79fb99de414f0dbe9ce05b762\", element=\"1b52b4bd-9ba6-46ed-84c9-0d848941c41c\")>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_listing_class = 'ui-organism-intersection__element.intersection-card-container'\n",
    "main_listings = browser.find_elements_by_class_name(main_listing_class)\n",
    "print(len(main_listings))\n",
    "main_listings[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "House listing is located in `Listing Card`, the children of `main_listing` element above. We will access this to retrieve Navigation link to its detailed listing information.\n",
    "We are going to try to a house list as below codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.rumah123.com/properti/jakarta-timur/hos10008254/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of using 1 listing\n",
    "listing_card_html = main_listings[2].get_attribute('outerHTML')\n",
    "soup_listing = BeautifulSoup(listing_card_html, \"html.parser\")\n",
    "\n",
    "# listing card properties\n",
    "nav_link = 'https://www.rumah123.com' + soup_listing.select('[title]')[1]['href']\n",
    "nav_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using above lines, we can collect all of the `listing_id` and `nav_link` from the main entry list, which contain more than one listing. Note that each listing has been isolated as a list of `WebElement` object so that we won't retrieve overlapped records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.rumah123.com/properti/jakarta-selatan/aps2723013/',\n",
       " 'https://www.rumah123.com/properti/jakarta-timur/hos10116318/',\n",
       " 'https://www.rumah123.com/properti/jakarta-timur/hos10008254/',\n",
       " 'https://www.rumah123.com/properti/jakarta-selatan/hos10914618/',\n",
       " 'https://www.rumah123.com/properti/jakarta-pusat/hos11325069/',\n",
       " 'https://www.rumah123.com/properti/jakarta-utara/hos9727104/',\n",
       " 'https://www.rumah123.com/properti/depok/hos10199621/',\n",
       " 'https://www.rumah123.com/properti/jakarta-timur/hos11324434/',\n",
       " 'https://www.rumah123.com/properti/jakarta-timur/hos9945268/',\n",
       " 'https://www.rumah123.com/properti/jakarta-pusat/hos8317620/',\n",
       " 'https://www.rumah123.com/properti/jakarta-selatan/hos11310013/',\n",
       " 'https://www.rumah123.com/properti/jakarta-barat/hos10771399/',\n",
       " 'https://www.rumah123.com/properti/jakarta-utara/hos11286910/',\n",
       " 'https://www.rumah123.com/properti/jakarta-barat/hos11295397/',\n",
       " 'https://www.rumah123.com/properti/jakarta-selatan/hos10934079/',\n",
       " 'https://www.rumah123.com/properti/jakarta-selatan/hos10402138/',\n",
       " 'https://www.rumah123.com/properti/jakarta-selatan/hos9644462/',\n",
       " 'https://www.rumah123.com/properti/jakarta-utara/hos11321935/',\n",
       " 'https://www.rumah123.com/properti/jakarta-pusat/hos11321908/',\n",
       " 'https://www.rumah123.com/properti/jakarta-barat/hos11320425/']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nav_links = []\n",
    "\n",
    "for listing in main_listings:\n",
    "    soup = BeautifulSoup(listing.get_attribute('innerHTML'))\n",
    "    listing_class = 'ui-organisms-card-r123-featured__middle-section__title'\n",
    "    nav_links.append(\n",
    "        'https://www.rumah123.com' + soup.select(('.' + listing_class))[0]['href']\n",
    "    )\n",
    "\n",
    "nav_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our scraping framework will loop-accessing all of the stored navigation link of house listing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Accessing specific `House Listing`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having information of each listing navigation link, we now begin to scrap information of each listing by repetitively accessing each of the link using our `Chrome Webdriver`.\n",
    "\n",
    "We have to identify each particular object that we want to scrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Listing Header**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center><img src=\"Scraped_Data\\pic\\4_Header.png\"/></center>\n",
    "\n",
    " *<center> Listing Header </center>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information:\n",
    "\n",
    "- Price\n",
    "- Title\n",
    "- Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.rumah123.com/properti/jakarta-timur/hos10008254/'\n",
    "browser.get(URL)\n",
    "time.sleep(float(random.uniform(5, 180, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Rumah Murah di Jalan Cipinang Baru Raya Jakarta Timur',\n",
       " 'price_currency': 'Rp',\n",
       " 'price_value': '2',\n",
       " 'price_unit': 'Miliar',\n",
       " 'address': 'Rawamangun, Jakarta Timur'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_class_name = 'ui-container.ui-property-page__main-container'\n",
    "header_element = browser.find_element_by_class_name(header_class_name)\n",
    "soup_header = BeautifulSoup(header_element.get_attribute('innerHTML'), 'html.parser')\n",
    "# scraping\n",
    "try: \n",
    "    currency, price, price_unit = \\\n",
    "        soup_header.select('.r123-listing-summary__price')[0].text.split()\n",
    "    title = soup_header.select('.r123-listing-summary__header-container-title')[0].text.strip()\n",
    "    address = soup_header.select('.r123-listing-summary__header-container-address')[0].text.strip()\n",
    "except AttributeError:\n",
    "    pass\n",
    "# compile header\n",
    "site_url = {'url': URL}\n",
    "header = dict(\n",
    "    title = title,\n",
    "    price_currency = currency,\n",
    "    price_value = price,\n",
    "    price_unit = price_unit,\n",
    "    address = address\n",
    ")\n",
    "\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Property Specifications**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed list of property specification will popped-up after we click *`menampilkan lebih banyak`*, as shown in below snapshot. We will retrieve the element after we *clicking* using the `WebDriver`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center><img src=\"Scraped_Data\\pic\\5_Listing_Popup_Button.png\"/></center>\n",
    "\n",
    " *<center> Listing specification </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <div role=\"button\" tabindex=\"0\" class=\"relative ui-content-half__selector\">...</div> is not clickable at point (403, 449). Other element would receive the click: <div class=\"ui-listing-specification__table--row\">...</div>\n  (Session info: chrome=106.0.5249.91)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32md:\\LEARN\\DATA SCIENCE\\2 WORKSPACE\\4 PROJECT\\2 JABODETABEK HOUSE PRICING\\jabodetabekhousepricing\\0 - Web Scraping.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LEARN/DATA%20SCIENCE/2%20WORKSPACE/4%20PROJECT/2%20JABODETABEK%20HOUSE%20PRICING/jabodetabekhousepricing/0%20-%20Web%20Scraping.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# commanding clicking\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LEARN/DATA%20SCIENCE/2%20WORKSPACE/4%20PROJECT/2%20JABODETABEK%20HOUSE%20PRICING/jabodetabekhousepricing/0%20-%20Web%20Scraping.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m details_popup_class_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelative.ui-content-half__selector\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/LEARN/DATA%20SCIENCE/2%20WORKSPACE/4%20PROJECT/2%20JABODETABEK%20HOUSE%20PRICING/jabodetabekhousepricing/0%20-%20Web%20Scraping.ipynb#X55sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m browser\u001b[39m.\u001b[39;49mfind_element_by_class_name(details_popup_class_name)\u001b[39m.\u001b[39;49mclick()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\web_access\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:80\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclick\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     79\u001b[0m     \u001b[39m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(Command\u001b[39m.\u001b[39;49mCLICK_ELEMENT)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\web_access\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:633\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[0;32m    632\u001b[0m params[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[1;32m--> 633\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\web_access\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:321\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 321\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    322\u001b[0m     response[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(\n\u001b[0;32m    323\u001b[0m         response\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    324\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\web_access\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:242\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m'\u001b[39m\u001b[39malert\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)\n\u001b[1;32m--> 242\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <div role=\"button\" tabindex=\"0\" class=\"relative ui-content-half__selector\">...</div> is not clickable at point (403, 449). Other element would receive the click: <div class=\"ui-listing-specification__table--row\">...</div>\n  (Session info: chrome=106.0.5249.91)\n"
     ]
    }
   ],
   "source": [
    "# commanding clicking\n",
    "details_popup_class_name = 'relative.ui-content-half__selector'\n",
    "browser.find_element_by_class_name(details_popup_class_name).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K. Tidur': '3',\n",
       " 'K. Mandi': '3',\n",
       " 'L. Tanah': '56 m²',\n",
       " 'L. Bangunan': '87 m²',\n",
       " 'Carport': '1',\n",
       " 'Tipe Properti': 'Rumah',\n",
       " 'Sertifikat': 'SHM - Sertifikat Hak Milik',\n",
       " 'Daya Listrik': '2200 mAh',\n",
       " 'Jumlah Lantai': '2',\n",
       " 'Tahun dibangun': '2022',\n",
       " 'Kondisi Properti': 'Baru',\n",
       " 'Kondisi Perabotan': 'Unfurnished',\n",
       " 'ID Iklan': 'hos10008254'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_element = browser.find_element_by_class_name('ui-listing-specification__table')\n",
    "details_soup = BeautifulSoup(details_element.get_attribute('innerHTML'), 'html.parser')\n",
    "# compile available details\n",
    "details = {}\n",
    "for spec in details_soup.select('.ui-listing-specification__table--row'):\n",
    "    label, value = [_.text for _ in spec.find_all('p')]\n",
    "    details.update({label: value})\n",
    "\n",
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Provided Facilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center><img src=\"Scraped_Data\\pic\\6_Facilities.png\"/></center>\n",
    "\n",
    " *<center> Provided facilities </center>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'facilities': 'Keamanan, CCTV'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facilities_element = browser.find_element_by_class_name('ui-facilities-portal__item-wrapper')\n",
    "facilities_soup = BeautifulSoup(facilities_element.get_attribute('innerHTML'), 'html.parser')\n",
    "\n",
    "facilities = {\n",
    "    'facilities': ', '.join({_.text for _ in facilities_soup.select('.ui-facilities-portal__item')})\n",
    "}\n",
    "\n",
    "facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Combining Scraped Data from a Single Listing Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From section `2.2A ccessing specific House Listing`, we have compiled several collections of scraped data as below:\n",
    "\n",
    "1. Records of **Listing URL**, stored in `url` variable \n",
    "2. Records of **Listing Header**, stored in `header` variable\n",
    "3. Records of **Property Details**, stored in `details` variable\n",
    "4. Records of **Provided Facilities**, stored in `facilities` variable\n",
    "\n",
    "Thus, a single observations of house listing will be presented as a `dictionary` of records, as explained in code below. We specifically use the dict `update` method to merge the records and ignoring the duplicated records (if any).\n",
    "\n",
    "Collection of observations will be stored as a **list of dictionaries**, which then can be processed using `pandas.DataFrame` constructor. More of this will be explained in the next chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Completing Web Scraping Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now begin to complete our framework by creating a program to iterate over listing pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper():\n",
    "    \"\"\" \"\"\"\n",
    "    def __init__(self, start_url):\n",
    "        self._URL = start_url\n",
    "        self._nav_links = []\n",
    "        self._observations = []\n",
    "        self._chrome_options = webdriver.ChromeOptions()\n",
    "        self._prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "        self._chrome_options.add_experimental_option('prefs', self._prefs)\n",
    "        self._browser = webdriver.Chrome('D:\\\\chromedriver.exe')\n",
    "\n",
    "        \n",
    "    def _main_page_accessor(self, url):\n",
    "        \"\"\" Collects navigation links from a single entry page\"\"\"\n",
    "        # Starts page access\n",
    "        self._browser.get(url)\n",
    "        # time.sleep(float(random.uniform(5, 120, 1)))\n",
    "        # Post access\n",
    "        main_listing_class_ = 'ui-organism-intersection__element.intersection-card-container'\n",
    "        main_listings_ = self._browser.find_elements_by_class_name(main_listing_class_)\n",
    "        links_ = []\n",
    "        for listing_ in main_listings_:\n",
    "            soup_ = BeautifulSoup(listing_.get_attribute('innerHTML'), 'html.parser')\n",
    "            listing_class_ = 'ui-organisms-card-r123-featured__middle-section__title'\n",
    "            links_.append(\n",
    "                'https://www.rumah123.com' + soup_.select(('.' + listing_class_))[0]['href']\n",
    "            )\n",
    "        self._nav_links = links_.copy()\n",
    "\n",
    "    def _listing_scraper(self, url):\n",
    "        scrap_data_ = {}\n",
    "        # Starts page access\n",
    "        self._browser.get(url)\n",
    "        #time.sleep(float(random.uniform(5, 120, 1)))\n",
    "        # Post access:\n",
    "        # 1. Scraping Header\n",
    "        header_class_name_ = 'ui-container.ui-property-page__main-container'\n",
    "        header_element_ = self._browser.find_element_by_class_name(header_class_name_)\n",
    "        soup_header_ = BeautifulSoup(header_element_.get_attribute('innerHTML'), 'html.parser')\n",
    "        try: \n",
    "            scrap_data_['currency'], scrap_data_['price'], scrap_data_['price_unit_scale'] = \\\n",
    "                soup_header_.select('.r123-listing-summary__price')[0].text.split()\n",
    "            scrap_data_['title'] = soup_header.select('.r123-listing-summary__header-container-title')[0].text.strip()\n",
    "            scrap_data_['address'] = soup_header.select('.r123-listing-summary__header-container-address')[0].text.strip()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        # 2. Scraping Property Specification\n",
    "        details_popup_class_name_ = 'relative.ui-content-half__selector'\n",
    "        self._browser.find_element_by_class_name(details_popup_class_name_).click()\n",
    "        details_element_ = self._browser.find_element_by_class_name('ui-listing-specification__table')\n",
    "        details_soup_ = BeautifulSoup(details_element_.get_attribute('innerHTML'), 'html.parser')\n",
    "        for spec in details_soup_.select('.ui-listing-specification__table--row'):\n",
    "            label_, value_ = [_.text.lower() for _ in spec.find_all('p')]\n",
    "            scrap_data_.update({label_: value_})\n",
    "        # 3. Scraping Provided Facilities\n",
    "        facilities_element_ = self._browser.find_element_by_class_name('ui-facilities-portal__item-wrapper')\n",
    "        facilities_soup_ = BeautifulSoup(facilities_element_.get_attribute('innerHTML'), 'html.parser')        \n",
    "        scrap_data_['facilities'] = \\\n",
    "            ', '.join({_.text for _ in facilities_soup_.select('.ui-facilities-portal__item')})\n",
    "        self._observations.append(scrap_data_)\n",
    " \n",
    "    def scrap(self, start_page, end_page):\n",
    "        start_page_ = start_page\n",
    "        end_page_ = end_page\n",
    "        for i in range(start_page_, end_page_ + 1):\n",
    "            entry_page_url_ = self._URL + f'&page={i}'    \n",
    "            self._main_page_accessor(entry_page_url_)\n",
    "            for link_ in self._nav_links:\n",
    "                self._listing_scraper(link_)\n",
    "        return self._observations\n",
    "\n",
    "\n",
    "    # Simple Testing\n",
    "    # def test_1(self):\n",
    "    #     self._main_page_accessor(self._URL)\n",
    "    #     return self._nav_links\n",
    "\n",
    "    def test_2(self):\n",
    "        self._listing_scraper(self._URL)\n",
    "        return self._observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 'test'}, {'b': 'test 2'}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_example = []\n",
    "dict_1 = dict(a = 'test')\n",
    "dict_2 = dict(b = 'test 2')\n",
    "list_example.append(dict_1)\n",
    "list_example.append(dict_2)\n",
    "\n",
    "list_example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'currency': 'Rp',\n",
       "  'price': '10,5',\n",
       "  'price_unit_scale': 'Miliar',\n",
       "  'title': 'Rumah Murah di Jalan Cipinang Baru Raya Jakarta Timur',\n",
       "  'address': 'Rawamangun, Jakarta Timur',\n",
       "  'K. Tidur': '5',\n",
       "  'K. Mandi': '5',\n",
       "  'L. Tanah': '230 m²',\n",
       "  'L. Bangunan': '550 m²',\n",
       "  'Carport': '2',\n",
       "  'Tipe Properti': 'Rumah',\n",
       "  'Sertifikat': 'SHM - Sertifikat Hak Milik',\n",
       "  'Daya Listrik': '6600 mAh',\n",
       "  'KT. Pembantu': '2',\n",
       "  'KM. Pembantu': '1',\n",
       "  'Garasi': '4',\n",
       "  'Jumlah Lantai': '3',\n",
       "  'Tahun dibangun': '2022',\n",
       "  'Kondisi Properti': 'Baru',\n",
       "  'Kondisi Perabotan': 'Furnished',\n",
       "  'Hadap': 'Utara',\n",
       "  'ID Iklan': 'hos11028271',\n",
       "  'facilities': 'Kolam Renang, Keamanan,  Jogging Track,  Ac,  Jalur Telepon,  Taman,  CCTV'}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_URL = 'https://www.rumah123.com/properti/jakarta-selatan/hos11028271/'\n",
    "WebScraper(TEST_URL).test_2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('web_access')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63de3f552b59bc0f4e942c3b929aad24c5a3dab61e77579e2f82111e07eb88c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
