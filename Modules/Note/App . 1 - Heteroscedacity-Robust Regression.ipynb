{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressHart(y, X, Z, **kwargs):\n",
    "    n = len(y)\n",
    "    if n != X.shape[0]:\n",
    "        raise ValueError('Size mismatch')\n",
    "    maxiterdef = 10000\n",
    "    toldef = 1e-08\n",
    "    test=0\n",
    "    options = dict(\n",
    "        intercept=True,\n",
    "        maxiter=maxiterdef,\n",
    "        type='art',\n",
    "        initialbeta=None, # shall be array of shape (n_features, ) for single target regression\n",
    "        initialgamma=None,\n",
    "        tol=toldef,\n",
    "        nocheck=False,\n",
    "        msgiter=0,\n",
    "        test=test\n",
    "    )\n",
    "    test = options['test']\n",
    "    reg = LinearRegression(fit_intercept=options['intercept'])\n",
    "    # number of predictors\n",
    "    if options['intercept']:\n",
    "        p = X.shape[1] + 1\n",
    "    else:\n",
    "        p = X.shape[1]\n",
    "    reg_results0 = reg.fit(X, y)\n",
    "    b0 = np.c_[reg_results0.intercept_, reg_results0.coef_] # b0 is array of shape (n_features, ) for single target regression\n",
    "    r = y - reg_results0.predict(X)\n",
    "    oldbeta = b0\n",
    "    sigma2 = r.T @ r / (n)\n",
    "    # loglikelihood of residual\n",
    "    logL_R = n * (1 + np.log(sigma2))\n",
    "    #  Initialization of gamma\n",
    "    #  Z = n-by-r matrix which contains the explanatory variables for\n",
    "    #  heteroskedasticity\n",
    "    Z_ = Z.copy\n",
    "    # if options['intercept']:\n",
    "    #     Z_ = add_constant(Z_)\n",
    "    response_gamma0 = n * np.square(r) / np.sum(np.square(r)) - 1\n",
    "    reg_gamma = reg.fit(Z, response_gamma0)\n",
    "    gamma0 = np.c_[reg_gamma.intercept_, reg_gamma.coef_]\n",
    "    # gamma\n",
    "    oldgamma = gamma0\n",
    "    # tolerance\n",
    "    tol = options['tol']\n",
    "    cont = 1\n",
    "    iter = 0\n",
    "    maxiter = options['maxiter']\n",
    "    delt = 1\n",
    "    th = 8\n",
    "    dold = np.c_[oldbeta, oldgamma]\n",
    "    print(f'{dold}')\n",
    "    while (cont == 1) & (iter < maxiter):\n",
    "        iter = iter + 1\n",
    "        if options['intercept']:\n",
    "            Zoldgamma = (np.c_[np.repeat(1, n), Z] @ oldgamma.T).flatten()\n",
    "        Zoldgamma[Zoldgamma < -th] = -th\n",
    "        Zoldgamma[Zoldgamma > th] = th\n",
    "        expZgamma = np.exp(Zoldgamma)\n",
    "        omegahat = 1 + expZgamma\n",
    "        sqrtweight = np.sqrt(omegahat)\n",
    "        reg_new = reg.fit(X, y, sample_weight=omegahat)\n",
    "        y_new = reg_new.predict(X)\n",
    "        newbeta = np.c_[reg_new.intercept_, reg_new.coef_]\n",
    "        newres2 = np.square(sqrtweight * (y - y_new))\n",
    "        newsigma2 = np.sum(newres2) / (n)\n",
    "        Qweights = expZgamma / (1 + expZgamma)\n",
    "        Zq = Z * Qweights.reshape(-1, 1)\n",
    "        newres2ori = y - y_new\n",
    "        yq = newres2ori / (newsigma2 * (1 + expZgamma))\n",
    "        reg_q = reg.fit(Zq, yq)\n",
    "        gamma_q = np.c_[reg_q.intercept_, reg_q.coef_]\n",
    "        newgamma = oldgamma + gamma_q * delt\n",
    "        dnew = np.c_[newbeta, newgamma]\n",
    "        print(f'{dnew}')\n",
    "        if (np.sum(np.square(dnew - dold)) / np.sum(np.square(dold))) > tol:\n",
    "            cont = 1\n",
    "            oldgamma = newgamma\n",
    "            dold=dnew\n",
    "        else:\n",
    "            cont = 0\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressHart(y, X, Z, **kwargs):\n",
    "    n = len(y)\n",
    "    if n != X.shape[0]:\n",
    "        raise ValueError('Size mismatch')\n",
    "    maxiterdef = 10000\n",
    "    toldef = 1e-12\n",
    "    test=0\n",
    "    options = dict(\n",
    "        intercept=True,\n",
    "        maxiter=maxiterdef,\n",
    "        type='art',\n",
    "        initialbeta=None, # shall be array of shape (n_features, ) for single target regression\n",
    "        initialgamma=None,\n",
    "        tol=toldef,\n",
    "        nocheck=False,\n",
    "        msgiter=0,\n",
    "        test=test\n",
    "    )\n",
    "    test = options['test']\n",
    "    reg = LinearRegression(fit_intercept=options['intercept'])\n",
    "    # number of predictors\n",
    "    if options['intercept']:\n",
    "        p = X.shape[1] + 1\n",
    "    else:\n",
    "        p = X.shape[1]\n",
    "    reg_results0 = reg.fit(X, y)\n",
    "    b0 = np.c_[reg_results0.intercept_, reg_results0.coef_] # b0 is array of shape (n_features, ) for single target regression\n",
    "    r = y - reg_results0.predict(X)\n",
    "    oldbeta = b0\n",
    "    sigma2 = r.T @ r / (n)\n",
    "    # loglikelihood of residual\n",
    "    logL_R = n * (1 + np.log(sigma2))\n",
    "    #  Initialization of gamma\n",
    "    #  Z = n-by-r matrix which contains the explanatory variables for\n",
    "    #  heteroskedasticity\n",
    "    Z_ = Z.copy\n",
    "    # if options['intercept']:\n",
    "    #     Z_ = add_constant(Z_)\n",
    "    response_gamma0 = n * np.square(r) / np.sum(np.square(r)) - 1\n",
    "    reg_gamma = reg.fit(Z, response_gamma0)\n",
    "    gamma0 = np.c_[reg_gamma.intercept_, reg_gamma.coef_]\n",
    "    # gamma\n",
    "    oldgamma = gamma0\n",
    "    # tolerance\n",
    "    tol = options['tol']\n",
    "    cont = 1\n",
    "    iter = 0\n",
    "    maxiter = options['maxiter']\n",
    "    delt = 0.5\n",
    "    th = 8\n",
    "    dold = np.c_[oldbeta, oldgamma]\n",
    "    print(f'{dold}')\n",
    "    while (cont == 1) & (iter < maxiter):\n",
    "        iter = iter + 1\n",
    "        if options['intercept']:\n",
    "            Zoldgamma = (np.c_[np.repeat(1, n), Z] @ oldgamma.T).flatten()\n",
    "        # Zoldgamma[Zoldgamma < -th] = -th\n",
    "        # Zoldgamma[Zoldgamma > th] = th\n",
    "        expZgamma = np.exp(Zoldgamma)\n",
    "        omegahat = 1 + expZgamma\n",
    "        weight = np.power(omegahat, -1)\n",
    "        sqrtweight = np.sqrt(weight)\n",
    "        reg_new = reg.fit(X, y, sample_weight=weight)\n",
    "        y_new = reg_new.predict(X)\n",
    "        newbeta = np.c_[reg_new.intercept_, reg_new.coef_]\n",
    "        newres2 = np.square(sqrtweight * (y - y_new))\n",
    "        newsigma2 = np.sum(newres2) / (n)\n",
    "        Qweights = expZgamma / (1 + expZgamma)\n",
    "        Zq = Z * Qweights.reshape(-1, 1)\n",
    "        newres2ori = y - y_new\n",
    "        yq = newres2ori / (newsigma2 * (1 + expZgamma))\n",
    "        reg_q = reg.fit(Zq, yq)\n",
    "        gamma_q = np.c_[reg_q.intercept_, reg_q.coef_]\n",
    "        newgamma = oldgamma + gamma_q * delt\n",
    "        dnew = np.c_[newbeta, newgamma]\n",
    "        print(f'{dnew}')\n",
    "        if (np.sum(np.square(dnew - dold)) / np.sum(np.square(dold))) > tol:\n",
    "            cont = 1\n",
    "            oldgamma = newgamma\n",
    "            dold=dnew\n",
    "        else:\n",
    "            cont = 0\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10280\\3806559073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregressHart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "regressHart(y, X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.c_[np.repeat(1, 1100), X] @ np.array([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_df = pd.read_csv('TradeH.csv', sep='\\t', header=None, names=['quantity', 'value'])\n",
    "\n",
    "X = trade_df['quantity'].values.reshape(-1, 1)\n",
    "y = trade_df['value'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(regressHart(y, X, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressHart(y, X, X)[np.argsort(X.flatten)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = regressHart(y, X, X)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg_result = reg.fit(X, y)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(np.sort(X.flatten()), regressHart(y, X, X)[np.argsort(X.flatten())], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg_result = reg.fit(X, y)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "ax.scatter(x=X, y=y)\n",
    "ax.plot(np.sort(X.flatten()), regressHart(y, X, X)[np.argsort(X.flatten())], color='red')\n",
    "ax.plot(np.sort(X.flatten()), reg_result.predict(X)[np.argsort(X.flatten())], color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv('X_train.csv')\n",
    "y_df = pd.read_csv('y_train.csv')\n",
    "\n",
    "\n",
    "X = X_df['building_size_m2'].values.reshape(-1, 1)\n",
    "y = y_df['price_in_rp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_df = pd.read_csv('X_train.csv')\n",
    "y_df = pd.read_csv('y_train.csv')\n",
    "\n",
    "\n",
    "X = X_df['building_size_m2'].values.reshape(-1, 1)\n",
    "y = y_df['price_in_rp'].values\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg_result = reg.fit(X, y)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "weighted_y = weight * 2.5e11\n",
    "ax.scatter(x=X, y=y)\n",
    "ax.plot(np.sort(X.flatten()), regressHart(y, X, X)[np.argsort(X.flatten())], color='red')\n",
    "ax.plot(np.sort(X.flatten()), reg_result.predict(X)[np.argsort(X.flatten())], color='black')\n",
    "ax.plot(np.sort(X.flatten()), weighted_y[np.argsort(X.flatten())], color='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressHart(y, X, Z, **kwargs):\n",
    "    n = len(y)\n",
    "    if n != X.shape[0]:\n",
    "        raise ValueError('Size mismatch')\n",
    "    maxiterdef = 10000\n",
    "    toldef = 1e-12\n",
    "    test=0\n",
    "    options = dict(\n",
    "        intercept=True,\n",
    "        maxiter=maxiterdef,\n",
    "        type='art',\n",
    "        initialbeta=None, # shall be array of shape (n_features, ) for single target regression\n",
    "        initialgamma=None,\n",
    "        tol=toldef,\n",
    "        nocheck=False,\n",
    "        msgiter=0,\n",
    "        test=test\n",
    "    )\n",
    "    test = options['test']\n",
    "    reg = LinearRegression(fit_intercept=options['intercept'])\n",
    "    # number of predictors\n",
    "    if options['intercept']:\n",
    "        p = X.shape[1] + 1\n",
    "    else:\n",
    "        p = X.shape[1]\n",
    "    reg_results0 = reg.fit(X, y)\n",
    "    b0 = np.c_[reg_results0.intercept_, reg_results0.coef_] # b0 is array of shape (n_features, ) for single target regression\n",
    "    r = y - reg_results0.predict(X)\n",
    "    oldbeta = b0\n",
    "    sigma2 = r.T @ r / (n)\n",
    "    # loglikelihood of residual\n",
    "    logL_R = n * (1 + np.log(sigma2))\n",
    "    #  Initialization of gamma\n",
    "    #  Z = n-by-r matrix which contains the explanatory variables for\n",
    "    #  heteroskedasticity\n",
    "    Z_ = Z.copy\n",
    "    # if options['intercept']:\n",
    "    #     Z_ = add_constant(Z_)\n",
    "    response_gamma0 = n * np.square(r) / np.sum(np.square(r)) - 1\n",
    "    reg_gamma = reg.fit(Z, response_gamma0)\n",
    "    gamma0 = np.c_[reg_gamma.intercept_, reg_gamma.coef_]\n",
    "    # gamma\n",
    "    oldgamma = gamma0\n",
    "    # tolerance\n",
    "    tol = options['tol']\n",
    "    cont = 1\n",
    "    iter = 0\n",
    "    maxiter = options['maxiter']\n",
    "    delt = 0.5\n",
    "    th = 8\n",
    "    dold = np.c_[oldbeta, oldgamma]\n",
    "    print(f'{dold}')\n",
    "    while (cont == 1) & (iter < maxiter):\n",
    "        iter = iter + 1\n",
    "        if options['intercept']:\n",
    "            Zoldgamma = (np.c_[np.repeat(1, n), Z] @ oldgamma.T).flatten()\n",
    "        # Zoldgamma[Zoldgamma < -th] = -th\n",
    "        # Zoldgamma[Zoldgamma > th] = th\n",
    "        expZgamma = np.exp(Zoldgamma)\n",
    "        omegahat = 1 + expZgamma\n",
    "        weight = np.power(omegahat, -1)\n",
    "        sqrtweight = np.sqrt(weight)\n",
    "        reg_new = reg.fit(X, y, sample_weight=weight)\n",
    "        y_new = reg_new.predict(X)\n",
    "        newbeta = np.c_[reg_new.intercept_, reg_new.coef_]\n",
    "        newres2 = np.square(sqrtweight * (y - y_new))\n",
    "        newsigma2 = np.sum(newres2) / (n)\n",
    "        Qweights = expZgamma / (1 + expZgamma)\n",
    "        Zq = Z * Qweights.reshape(-1, 1)\n",
    "        newres2ori = y - y_new\n",
    "        yq = newres2ori / (newsigma2 * (1 + expZgamma))\n",
    "        reg_q = reg.fit(Zq, yq)\n",
    "        gamma_q = np.c_[reg_q.intercept_, reg_q.coef_]\n",
    "        newgamma = oldgamma + gamma_q * delt\n",
    "        dnew = np.c_[newbeta, newgamma]\n",
    "        print(f'{dnew}')\n",
    "        if (np.sum(np.square(dnew - dold)) / np.sum(np.square(dold))) > tol:\n",
    "            cont = 1\n",
    "            oldgamma = newgamma\n",
    "            dold=dnew\n",
    "        else:\n",
    "            cont = 0\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg_result = reg.fit(X, y)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "weight = regressHart(y, X, X)\n",
    "ax.plot(np.sort(X.flatten()), regressHart(y, X, X)[np.argsort(X.flatten())], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressHart(y, X, Z, **kwargs):\n",
    "    n = len(y)\n",
    "    if n != X.shape[0]:\n",
    "        raise ValueError('Size mismatch')\n",
    "    maxiterdef = 10000\n",
    "    toldef = 1e-12\n",
    "    test=0\n",
    "    options = dict(\n",
    "        intercept=True,\n",
    "        maxiter=maxiterdef,\n",
    "        type='art',\n",
    "        initialbeta=None, # shall be array of shape (n_features, ) for single target regression\n",
    "        initialgamma=None,\n",
    "        tol=toldef,\n",
    "        nocheck=False,\n",
    "        msgiter=0,\n",
    "        test=test\n",
    "    )\n",
    "    test = options['test']\n",
    "    reg = LinearRegression(fit_intercept=options['intercept'])\n",
    "    # number of predictors\n",
    "    if options['intercept']:\n",
    "        p = X.shape[1] + 1\n",
    "    else:\n",
    "        p = X.shape[1]\n",
    "    reg_results0 = reg.fit(X, y)\n",
    "    b0 = np.c_[reg_results0.intercept_, reg_results0.coef_] # b0 is array of shape (n_features, ) for single target regression\n",
    "    r = y - reg_results0.predict(X)\n",
    "    oldbeta = b0\n",
    "    sigma2 = r.T @ r / (n)\n",
    "    # loglikelihood of residual\n",
    "    logL_R = n * (1 + np.log(sigma2))\n",
    "    #  Initialization of gamma\n",
    "    #  Z = n-by-r matrix which contains the explanatory variables for\n",
    "    #  heteroskedasticity\n",
    "    Z_ = Z.copy\n",
    "    # if options['intercept']:\n",
    "    #     Z_ = add_constant(Z_)\n",
    "    response_gamma0 = n * np.square(r) / np.sum(np.square(r)) - 1\n",
    "    reg_gamma = reg.fit(Z, response_gamma0)\n",
    "    gamma0 = np.c_[reg_gamma.intercept_, reg_gamma.coef_]\n",
    "    # gamma\n",
    "    oldgamma = gamma0\n",
    "    # tolerance\n",
    "    tol = options['tol']\n",
    "    cont = 1\n",
    "    iter = 0\n",
    "    maxiter = options['maxiter']\n",
    "    delt = 0.5\n",
    "    th = 8\n",
    "    dold = np.c_[oldbeta, oldgamma]\n",
    "    print(f'{dold}')\n",
    "    while (cont == 1) & (iter < maxiter):\n",
    "        iter = iter + 1\n",
    "        if options['intercept']:\n",
    "            Zoldgamma = (np.c_[np.repeat(1, n), Z] @ oldgamma.T).flatten()\n",
    "        # Zoldgamma[Zoldgamma < -th] = -th\n",
    "        # Zoldgamma[Zoldgamma > th] = th\n",
    "        expZgamma = np.exp(Zoldgamma)\n",
    "        omegahat = 1 + expZgamma\n",
    "        weight = np.power(omegahat, -1)\n",
    "        sqrtweight = np.sqrt(weight)\n",
    "        reg_new = reg.fit(X, y, sample_weight=weight)\n",
    "        y_new = reg_new.predict(X)\n",
    "        newbeta = np.c_[reg_new.intercept_, reg_new.coef_]\n",
    "        newres2 = np.square(sqrtweight * (y - y_new))\n",
    "        newsigma2 = np.sum(newres2) / (n)\n",
    "        Qweights = expZgamma / (1 + expZgamma)\n",
    "        Zq = Z * Qweights.reshape(-1, 1)\n",
    "        newres2ori = y - y_new\n",
    "        yq = newres2ori / (newsigma2 * (1 + expZgamma))\n",
    "        reg_q = reg.fit(Zq, yq)\n",
    "        gamma_q = np.c_[reg_q.intercept_, reg_q.coef_]\n",
    "        newgamma = oldgamma + gamma_q * delt\n",
    "        dnew = np.c_[newbeta, newgamma]\n",
    "        print(f'{dnew}')\n",
    "        if (np.sum(np.square(dnew - dold)) / np.sum(np.square(dold))) > tol:\n",
    "            cont = 1\n",
    "            oldgamma = newgamma\n",
    "            dold=dnew\n",
    "        else:\n",
    "            cont = 0\n",
    "    return reg_new.predict(np.array([500]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressHart(y, X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (187259090.py, line 98)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Audimas Firian\\AppData\\Local\\Temp\\ipykernel_10280\\187259090.py\"\u001b[1;36m, line \u001b[1;32m98\u001b[0m\n\u001b[1;33m    d =\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "class RegressHART(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, fit_intercept=True, max_iter=1000, \n",
    "            initialbeta=None, initialgamma=None, tol=1e-8):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.initialbeta = initialbeta\n",
    "        self.initialgamma = initialgamma\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def _estimate_gamma(self, X, y, Z):\n",
    "        \"\"\" Estimate gamma for the parametric weight\"\"\"\n",
    "        reg = LinearRegression(fit_intercept=self.fit_intercept)\n",
    "        reg_result0 = reg.fit(X, y)\n",
    "        if self.fit_intercept:\n",
    "            self._n_params = reg_result0.n_features_in_ + 1\n",
    "        else:\n",
    "            self._n_params = reg_result0.n_features_in_\n",
    "        # since ._validate_data() has been performed by sklearn estimator,\n",
    "        # length for response (n_samples, ) has been checked to match with\n",
    "        # regressor (n_samples, n_features), so:\n",
    "        self._n_samples = len(y)\n",
    "        residual = y - reg_result0.predict(X)\n",
    "        sigma2 = \\\n",
    "            residual.T @ residual / (self._n_samples - self._n_params) # estimate of variance\n",
    "        # initial estimate of gamma, using Z and \n",
    "        #\n",
    "        response_gamma0 = \\\n",
    "            self._n_samples * np.square(residual) / np.sum(np.square(residual)) - 1\n",
    "        # Shape of Z (n_samples, n_heteroscedastic_features)\n",
    "        # will also be verified by sklearn estimator to match with \n",
    "        # response y (n_samples, )\n",
    "        reg_gamma = reg.fit(Z, response_gamma0)\n",
    "        if self.fit_intercept:\n",
    "            return reg_gamma.intercept_, reg_gamma.coef_\n",
    "        return reg_gamma.coef_\n",
    "\n",
    "    def _weighted_regressor(self, X, y, Z, gamma):\n",
    "        if self.fit_intercept:\n",
    "            zgamma = (np.c_[np.repeat(1, self._n_samples), Z] @ gamma.T).flatten()\n",
    "        else:\n",
    "            zgamma = (Z @ gamma.T).flatten()\n",
    "        expzgamma = np.exp(zgamma)\n",
    "        weight = np.power((1 + expzgamma), -1)\n",
    "        reg = self._reg.fit(X, y, sample_weight=weight)\n",
    "        return reg\n",
    "    \n",
    "    def _scoring(self, X, y, Z, fitted_regressor, gamma):\n",
    "        if self.fit_intercept:\n",
    "            zgamma = (np.c_[np.repeat(1, self._n_samples), Z] @ gamma.T).flatten()\n",
    "        else:\n",
    "            zgamma = (Z @ gamma.T).flatten()\n",
    "        y_predict = fitted_regressor.predict(X)\n",
    "        expzgamma = np.exp(zgamma)\n",
    "        weight = np.power((1 + expzgamma), -1)\n",
    "        sqrtweight = np.sqrt(weight)\n",
    "        weighted_res2 = np.square(sqrtweight * (y - y_predict))\n",
    "        sigma2 = np.sum(weighted_res2) / (self._n_samples - self._n_params)\n",
    "        q = expzgamma / (1 + expzgamma)\n",
    "        zq = Z * q.reshape(-1, 1)\n",
    "        res2 = np.square(y - y_predict)\n",
    "        yq = res2 / (sigma2 * (1 + expzgamma))\n",
    "        reg_q = self._reg.fit(zq, yq)\n",
    "        gamma_q = np.c_[reg_q.intercept_, reg_q.coef_]\n",
    "        return gamma_q\n",
    "\n",
    "    def fit(self, X, y, Z):\n",
    "        # since we wrap sklearn function, ._validate_data() will be\n",
    "        # performed under sklearn estimator\n",
    "        self._n_params = None\n",
    "        self._n_samples = None\n",
    "        self._reg = LinearRegression(fit_intercept=self.fit_intercept)\n",
    "        if self.initial_gamma:\n",
    "            gamma = self.initial_gamma\n",
    "        else:\n",
    "            if self.fit_intercept:\n",
    "                gamma_intercept, gamma_coef = self._estimate_gamma(X, y, Z)\n",
    "                gamma = np.c_[gamma_intercept, gamma_coef]\n",
    "            else:\n",
    "                gamma = self._estimate_gamma(X, y, Z)\n",
    "        # initiate iter k + 1 until tolerance satisfied\n",
    "        # or max_iter excedeed\n",
    "        gamma_arr = gamma\n",
    "        reg_result_arr = np.array([self._weighted_regressor(X, y, Z, gamma)])\n",
    "        if self.fit_intercept:\n",
    "            reg_params_arr = \\\n",
    "                np.c_[np.array(reg_result_arr[0].intercept_), reg_result_arr[0].coef_]\n",
    "        else:\n",
    "            reg_params_arr = reg_result_arr[0].coef_\n",
    "        d_arr = ...\n",
    "        iter = 1\n",
    "        delt = 0.9\n",
    "        for i in range(self.max_iter):\n",
    "            gamma_q = self._scoring(X, y, Z, reg_result_arr[i], gamma_arr[i])\n",
    "            gamma_arr = np.r_[gamma_arr, (gamma_arr[i] + delt * gamma_q)]\\\n",
    "                .reshape(i + 2, gamma_arr[i].shape[0])\n",
    "            reg_result_arr = \\\n",
    "                np.r_[reg_result_arr, self._weighted_regressor(X, y, Z, gamma_arr[i + 1])]\\\n",
    "                    .reshape(-1, 1)\n",
    "            reg_params_arr = \\\n",
    "                np.r_[\n",
    "                    reg_params_arr,\n",
    "                    np.c_[np.array(reg_result_arr[i + 1].intercept_), \n",
    "                        reg_result_arr[i + 1].coef_]\n",
    "                ].reshape(i + 2, reg_params_arr[0].shape[1])\n",
    "            d_new = ...\n",
    "            d_arr = np.r_[d_arr, d_new]\n",
    "            tol = np.sum(np.square(d_arr[i + 1] - d_arr[i])) / np.sum(np.square(d_arr[i]))\n",
    "            if tol < self.tol:\n",
    "                break\n",
    "        # Final converged parameter\n",
    "        gamma = gamma_arr[-1]\n",
    "        if self.fit_intercept:\n",
    "            zgamma = (np.c_[np.repeat(1, self._n_samples), Z] @ gamma.T).flatten()\n",
    "        else:\n",
    "            zgamma = (Z @ gamma.T).flatten()   \n",
    "        expzgamma = np.exp(zgamma)\n",
    "        weight = np.power((1 + expzgamma), -1)    \n",
    "        self._reg_result = reg_result_arr[-1]\n",
    "        self.coef_ = self.reg_result.coef_\n",
    "        self.intercept_ = self.reg_result.intercept_\n",
    "        self.n_features_in_ = self.reg_result.n_features_in\n",
    "        self.feature_names_in_ = self.reg_result.feature_names_in_\n",
    "        self.gamma_ = gamma_arr\n",
    "        self.weight_ = weight\n",
    "        self.n_iter_ = iter\n",
    "        return self      \n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self)\n",
    "        return self._reg_result.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        while (iter < self.max_iter) & (tol > self.tol):\n",
    "            # calculate weight at k = 1 (inital iteration)\n",
    "            # k = 1 regression weight is based on provided or estimated inital gamma\n",
    "            # also store iterated gamma and weight\n",
    "            expzgamma = np.exp(zgamma)\n",
    "            weight = np.power((1 + expzgamma), -1)\n",
    "            # initial regression for k = 1 using estimated weight\n",
    "            # we also store iterated coefficient\n",
    "            self._reg_result = self._reg.fit(X, y, sample_weight=weight)\n",
    "            if self.fit_intercept:\n",
    "                reg_params = np.c_[np.array(self._reg_result.intercept_), self._reg_result.coef_]\n",
    "            else:\n",
    "                reg_params = self._reg_result.coef_\n",
    "            if iter == 1:\n",
    "                self.iterated_params_ = reg_params\n",
    "            else:\n",
    "                self.iterated_params_ = np.r_[self.iterated_params_, reg_params]\n",
    "            # initiate scoring for gamma\n",
    "            gamma_q = self._scoring(X, y, Z, self._reg_result, zgamma)\n",
    "            delta = 0.8\n",
    "            gamma_new = gamma +  gamma_q * delta\n",
    "            # properties of k + 1\n",
    "            zgamma_new = (Z @ gamma_new.T).flatten()\n",
    "            expzgamma_new = np.exp(zgamma_new)\n",
    "            weight = np.power((1 + expzgamma_new), -1)\n",
    "            reg_params_new = \n",
    "            # iteration tolerance\n",
    "            d = np.c_[reg_params, gamma]\n",
    "            d_new = \n",
    "            tol = np.sum(np.square(d_new - d)) / np.sum(np.square(d))\n",
    "            # if tol is not satisfied, loop will be performed,\n",
    "            # gamma will be replaced by scoring algorithm result\n",
    "            # so that first line of the loop will consider new gamma\n",
    "            # instead of estimated gamma\n",
    "            if tol > self.tol:\n",
    "                gamma = gamma_new\n",
    "                zgamma = (Z @ gamma.T).flatten()\n",
    "                self.iterated_gamma = np.r_[self.iterated_gamma_, gamma_new]\n",
    "                iter += 1\n",
    "        self.coef_ = reg_result.coef_\n",
    "        self.intercept_ = reg_result.intercept_\n",
    "        self.n_features_in_ = reg_result.n_features_in\n",
    "        self.feature_names_in_ = reg_result.feature_names_in_\n",
    "        self.gamma_ = gamma\n",
    "        self.weight_ = weight\n",
    "        self.n_iter_ = iter\n",
    "        return self\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "c = np.array([7, 8, 9])\n",
    "\n",
    "d = np.append(a, b).reshape(2, 3)\n",
    "e = np.append(d, c).reshape(3, 3)\n",
    "\n",
    "a.shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2])\n",
    "\n",
    "np.r_[a, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressHart(y, X, Z, **kwargs):\n",
    "    n = len(y)\n",
    "    if n != X.shape[0]:\n",
    "        raise ValueError('Size mismatch')\n",
    "    maxiterdef = 10000\n",
    "    toldef = 1e-12\n",
    "    test=0\n",
    "    options = dict(\n",
    "        intercept=True,\n",
    "        maxiter=maxiterdef,\n",
    "        type='art',\n",
    "        initialbeta=None, # shall be array of shape (n_features, ) for single target regression\n",
    "        initialgamma=None,\n",
    "        tol=toldef,\n",
    "        nocheck=False,\n",
    "        msgiter=0,\n",
    "        test=test\n",
    "    )\n",
    "    test = options['test']\n",
    "    reg = LinearRegression(fit_intercept=options['intercept'])\n",
    "    # number of predictors\n",
    "    if options['intercept']:\n",
    "        p = X.shape[1] + 1\n",
    "    else:\n",
    "        p = X.shape[1]\n",
    "    reg_results0 = reg.fit(X, y)\n",
    "    b0 = np.c_[reg_results0.intercept_, reg_results0.coef_] # b0 is array of shape (n_features, ) for single target regression\n",
    "    r = y - reg_results0.predict(X)\n",
    "    oldbeta = b0\n",
    "    sigma2 = r.T @ r / (n)\n",
    "    # loglikelihood of residual\n",
    "    logL_R = n * (1 + np.log(sigma2))\n",
    "    #  Initialization of gamma\n",
    "    #  Z = n-by-r matrix which contains the explanatory variables for\n",
    "    #  heteroskedasticity\n",
    "    Z_ = Z.copy\n",
    "    # if options['intercept']:\n",
    "    #     Z_ = add_constant(Z_)\n",
    "    response_gamma0 = n * np.square(r) / np.sum(np.square(r)) - 1\n",
    "    reg_gamma = reg.fit(Z, response_gamma0)\n",
    "    gamma0 = np.c_[reg_gamma.intercept_, reg_gamma.coef_]\n",
    "    # gamma\n",
    "    oldgamma = gamma0\n",
    "    # tolerance\n",
    "    tol = options['tol']\n",
    "    cont = 1\n",
    "    iter = 0\n",
    "    maxiter = options['maxiter']\n",
    "    delt = 0.5\n",
    "    th = 8\n",
    "    dold = np.c_[oldbeta, oldgamma]\n",
    "    print(f'{dold}')\n",
    "    while (cont == 1) & (iter < maxiter):\n",
    "        iter = iter + 1\n",
    "        if options['intercept']:\n",
    "            Zoldgamma = (np.c_[np.repeat(1, n), Z] @ oldgamma.T).flatten()\n",
    "        # Zoldgamma[Zoldgamma < -th] = -th\n",
    "        # Zoldgamma[Zoldgamma > th] = th\n",
    "        expZgamma = np.exp(Zoldgamma)\n",
    "        omegahat = 1 + expZgamma\n",
    "        weight = np.power(omegahat, -1)\n",
    "        sqrtweight = np.sqrt(weight)\n",
    "        reg_new = reg.fit(X, y, sample_weight=weight)\n",
    "        y_new = reg_new.predict(X)\n",
    "        newbeta = np.c_[reg_new.intercept_, reg_new.coef_]\n",
    "        newres2 = np.square(sqrtweight * (y - y_new))\n",
    "        newsigma2 = np.sum(newres2) / (n)\n",
    "        Qweights = expZgamma / (1 + expZgamma)\n",
    "        Zq = Z * Qweights.reshape(-1, 1)\n",
    "        newres2ori = y - y_new\n",
    "        yq = newres2ori / (newsigma2 * (1 + expZgamma))\n",
    "        reg_q = reg.fit(Zq, yq)\n",
    "        gamma_q = np.c_[reg_q.intercept_, reg_q.coef_]\n",
    "        newgamma = oldgamma + gamma_q * delt\n",
    "        dnew = np.c_[newbeta, newgamma]\n",
    "        print(f'{dnew}')\n",
    "        if (np.sum(np.square(dnew - dold)) / np.sum(np.square(dold))) > tol:\n",
    "            cont = 1\n",
    "            oldgamma = newgamma\n",
    "            dold=dnew\n",
    "        else:\n",
    "            cont = 0\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X, y).predict(X)\n",
    "\n",
    "reg.coef_ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2892b95998397e64822f38de2e41a1410cc5bda2d9d70e92f4ade4b6aa0470a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
